# âš”ï¸ Gladiator Duel AI - Q-Learning Project

> **Bu proje, Unity Oyun Motoru kullanÄ±larak geliÅŸtirilmiÅŸ, 2. aÅŸamasÄ±nda Q-Learning (Reinforcement Learning) yapay zeka algoritmasÄ± entegre edilmiÅŸ sÄ±ra tabanlÄ± bir strateji oyunudur.**

ğŸ® **TarayÄ±cÄ±da Oyna (WebGL):** https://elifnurbeycan.itch.io/gladiator-duel

---

## ğŸ“¸ Oyun Ä°Ã§i GÃ¶rseller


<img width="957" height="597" alt="Oyun EkranÄ±" src="https://github.com/user-attachments/assets/04f3d776-8472-49c5-9ace-be3454e1ed6d" />

---

## ğŸ§  Yapay Zeka (Q-Learning) Mimarisi

Projenin bu aÅŸamasÄ±nda, dÃ¼ÅŸman karakteri (`EnemyAgent.cs`) Ã¶nceden tanÄ±mlanmÄ±ÅŸ kurallar yerine, Ã§evresini gÃ¶zlemleyerek ve deneme-yanÄ±lma yoluyla Ã¶ÄŸrenen bir **Q-Learning AjanÄ±na** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

### ğŸ¯ Ã–dÃ¼l ve Ceza Tablosu (Reward System)
AjanÄ±n eÄŸitimi sÄ±rasÄ±nda davranÄ±ÅŸlarÄ±nÄ± ÅŸekillendirmek iÃ§in kod iÃ§erisinde (`EnemyAgent.cs`) aÅŸaÄŸÄ±daki Ã¶dÃ¼l/ceza mekanizmasÄ± kurulmuÅŸtur:

| Durum / Aksiyon | Puan (Ã–dÃ¼l/Ceza) | AmaÃ§ |
| :--- | :--- | :--- |
| **ğŸ† MaÃ§Ä± Kazanma** | `+50 Puan` | Ana hedefi gerÃ§ekleÅŸtirmek. |
| **ğŸ’€ MaÃ§Ä± Kaybetme** | `-20 Puan` | Hayatta kalmayÄ± teÅŸvik etmek. |
| **âš”ï¸ Rakibe Hasar Verme** | `+Hasar MiktarÄ±` | SaldÄ±rganlÄ±ÄŸÄ± artÄ±rmak (Ã–rn: 20 hasar = +20 Puan). |
| **ğŸ¹ Uzaktan SaldÄ±rÄ± (Ranged)** | `+10 Puan` | Mermisi varken uzaktan dÃ¶vÃ¼ÅŸÃ¼ teÅŸvik etmek. |
| **ğŸš« Ä°mkansÄ±z Hamle** | `-50 Puan` | ManasÄ± yetmediÄŸi veya mesafesi yetmediÄŸi halde hamle yapmaya Ã§alÄ±ÅŸÄ±rsa aÄŸÄ±r ceza alÄ±r. |
| **ğŸ§± Duvara Ã‡arpma** | `-20 Puan` | Harita sÄ±nÄ±rÄ±ndayken daha fazla geri gitmeye Ã§alÄ±ÅŸmasÄ±nÄ± engellemek. |
| **ğŸƒ Rakibe YaklaÅŸma** | `-5 Puan (YakÄ±nken)` | Zaten "Close" mesafedeyken Ã¼zerine yÃ¼rÃ¼meye Ã§alÄ±ÅŸmasÄ±nÄ± engellemek. |
| **ğŸ’¤ MantÄ±klÄ± Dinlenme** | `+10 Puan` | ManasÄ± azaldÄ±ÄŸÄ±nda (`<20`) dinlenmeyi Ã¶ÄŸrenmesi iÃ§in teÅŸvik. |

### âš™ï¸ Hiperparametreler (Hyperparameters)
EÄŸitim sÃ¼recinde aÅŸaÄŸÄ±daki Q-Learning parametreleri kullanÄ±lmÄ±ÅŸtÄ±r:

* **Learning Rate (Alpha):** `0.5` (Yeni tecrÃ¼belerin, eski bilgilerin Ã¼zerine yazÄ±lma hÄ±zÄ±.)
* **Discount Factor (Gamma):** `0.8` (Gelecekteki Ã¶dÃ¼llerin ÅŸimdiki karara etkisi.)
* **Exploration Rate (Epsilon):** `0.1` (EÄŸitilmiÅŸ modda rastgele hareket etme ihtimali minimuma indirilmiÅŸtir.)

### ğŸ’¾ Model YÃ¶netimi
EÄŸitilen veriler (Q-Table), oyun iÃ§erisinde **`Resources/BlueBrain.json`** dosyasÄ±nda saklanmaktadÄ±r. WebGL sÃ¼rÃ¼mÃ¼nde oyun, bu dosyayÄ± otomatik olarak belleÄŸe yÃ¼kler ve ajan eÄŸitimli verilerle oynar.

---

## ğŸ•¹ï¸ OynanÄ±ÅŸ ve Kontrol MekaniÄŸi

Oyun, butonlar aracÄ±lÄ±ÄŸÄ±yla sÄ±ra tabanlÄ± (Turn-Based) olarak oynanÄ±r.

* **Kontroller:** Ekrandaki butonlara tÄ±klayarak aksiyon seÃ§imi yapÄ±lÄ±r.
* **MenÃ¼:** `ESC` tuÅŸu ile ana menÃ¼ye dÃ¶nÃ¼lebilir.

### ğŸ® Aksiyon Listesi ve Maliyetler

Her karakterin **Can (HP)**, **Mana** ve **Mermi (Ammo)** kaynaklarÄ± vardÄ±r. Kod iÃ§erisinde tanÄ±mlÄ± maliyetler ÅŸÃ¶yledir:

| Aksiyon | Gereksinim (Cost) | Etki / Detay |
| :--- | :--- | :--- |
| **Move (Ä°leri/Geri)** | `4 Mana` | Mesafeyi (Close/Mid/Far) deÄŸiÅŸtirir. |
| **Ranged Attack** | `12 Mana` + `1 Ammo` | 15-20 arasÄ± hasar verir. *(Sadece Mid/Far mesafede)* |
| **Melee Attack** | `20 Mana` | 20-30 arasÄ± yÃ¼ksek hasar verir. *(Sadece Close mesafede)* |
| **Armor Up** | `15 Mana` | 2 tur boyunca alÄ±nan hasarÄ± %30 azaltÄ±r. |
| **Sleep (Dinlen)** | `0 Mana` | Turu pas geÃ§er, `+40 Mana` yeniler. |

---

## ğŸ› ï¸ Kurulum ve Test

Projeyi Unity EditÃ¶r'de aÃ§mak veya test etmek iÃ§in:

1.  `Scenes/MainMenu` sahnesini aÃ§Ä±n.
2.  Play tuÅŸuna basÄ±n.
3.  **"Yapay Zeka YÃ¼kle"** butonuna basarak eÄŸitilmiÅŸ Q-Learning modeli ile oynayÄ±n.
4.  **"Rastgele BaÅŸla"** butonu, ajanÄ±n beynini devre dÄ±ÅŸÄ± bÄ±rakÄ±r ve tamamen rastgele oynamasÄ±nÄ± saÄŸlar (AI farkÄ±nÄ± gÃ¶rmek iÃ§in).

---

**GeliÅŸtirici:** Elif Nur Beycan
**Ders:** Bilgisayar MÃ¼hendisliÄŸi - Oyun Programlama Projesi
